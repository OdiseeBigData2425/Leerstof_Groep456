{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDFS\n",
    "\n",
    "HDFS is het distributed file system van Hadoop dat de basis vormt voor een breed gamma van applicaties, waaronder MapReduce.\n",
    "Dit framework maakt het mogelijk om niet-gespecialiseerde hardware te gebruiken om eenvoudig datacenters op te zetten of rekenclusters te beheren.\n",
    "HDFS bereikt dit doel op een aantal manieren:\n",
    "* Ten eerste wordt een file opgedeeld in verschillende blokken. Deze worden verdeeld over verschillende computers zodat code meerdere delen van het bestand kan gebruiken in parallel om zo de benodigde rekenkracht te verdelen over meerdere toestellen.\n",
    "* Daarnaast worden de blokken ook gedupliceerd om zo fout-toleranter te zijn in het geval van een crash (hardware of software), stroomstoring, netwerkonderbreking.\n",
    "\n",
    "Om dit te bereiken gebruikt Hadoop een Master-Slave architectuur dat bestaat uit een enkele namenode (master) en meerdere datanodes (slaves).\n",
    "De namenode houdt bij hoeveel datanodes er actief zijn, welke blokken ze hebben en welke blokken bij welke file horen.\n",
    "Indien er een datanode crasht gaat deze server dit detecteren en dit oplossen door de nodige blokken te kopieren van een andere datanode zodat er steeds voldoende kopies in het systeem aanwezig zijn.\n",
    "Bij elke actie die uitgevoerd moet worden in het HDFS moet er steeds gevraagd worden aan de namenode welke blokken op welke datanodes we nodig hebben voor de gewenste file uit te lezen of code voor uit te voeren.\n",
    "Het is dus duidelijk dat deze namenode een single-point-of-failure is wat ideaal is voor de availability van de cluster.\n",
    "Dit kan opgelost worden door HDFS te runnen in een high-availability mode wat ervoor zorgt dat er steeds een backup aanwezig is voor de namenode die zeer snel de werking kan overnemen.\n",
    "Deze structuur maakt het eenvoudig om aan horizontal scaling te doen door extra servers toe te voegen zonder dat er downtime is voor de hele cluster.\n",
    "\n",
    "Dit resulteer in de volgende kenmerken van HDFS:\n",
    "* High Throughput\n",
    "* Scalability\n",
    "* High Availability\n",
    "* Data Reliability\n",
    "* Fault Tolerance\n",
    "\n",
    "## Starten en stoppen van de cluster\n",
    "\n",
    "De cluster kan gestart worden door alle docker containers te starten die gedefinieerd worden in de yaml-file.\n",
    "Dit kan via de docker desktop gui of via de command line door middel van het docker-compose commando.\n",
    "Stoppen kan dan via dezelfde methodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Communiceren met het HDFS\n",
    "\n",
    "Er zijn verschillende manieren om dit distributed bestandssysteem te gebruiken.\n",
    "Ten eerste kan je gebruik maken van een command line interface (CLI) om bestanden uit te lezen, op te laden, ...\n",
    "Daarnaast zijn er ook wrappers voor verschillende talen die toelaten om rechtstreeks vanuit code te interageren met het HDFS.\n",
    "De voordelen van deze wrappers over een CLI zijn:\n",
    "* Flexibiler om te interageren in applicaties.\n",
    "* Gebruiksvriendelijker en gemakkelijker om te automatiseren.\n",
    "* Eenvoudiger in onderhoud en te debuggen\n",
    "* Volledige functionaliteit van een programmeertaal kan gebruikt worden zoals OO.\n",
    "\n",
    "### Instantiering van een client\n",
    "\n",
    "Veel verschillende talen beschikken over een wrapper om te communiceren met een HDFS.\n",
    "In deze cursus gaan we gebruik maken van [InsecureClient in hdfscli](https://hdfscli.readthedocs.io/en/latest/quickstart.html) wrapper.\n",
    "De eerste stap in het gebruik van de wrapper is te bepalen hoe de namenode van het hdfs gevonden kan worden.\n",
    "Dit gebeurt als volgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accessTime': 0,\n",
       " 'blockSize': 0,\n",
       " 'childrenNum': 2,\n",
       " 'fileId': 16385,\n",
       " 'group': 'supergroup',\n",
       " 'length': 0,\n",
       " 'modificationTime': 1740043646546,\n",
       " 'owner': 'root',\n",
       " 'pathSuffix': '',\n",
       " 'permission': '755',\n",
       " 'replication': 0,\n",
       " 'snapshotEnabled': True,\n",
       " 'storagePolicy': 0,\n",
       " 'type': 'DIRECTORY'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hdfs import InsecureClient\n",
    "\n",
    "# maak de connectie met het hdfs\n",
    "client = InsecureClient('http://localhost:9870', 'bigdata')\n",
    "# localhost:9870 is de UI van het hdfs (hoe kan ik aan de namenode)\n",
    "# bigdata is de user die geconfigureerd is op het hdfs\n",
    "\n",
    "client.status('/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Aanmaken van files en directories\n",
    "\n",
    "Om nu bestanden en folders aan te maken op dit distributed file systeem kunnen onderstaande functies gebruikt worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make directories\n",
    "if client.status('hdfs456', strict=False) is None: # standaard throwed status een error als de file niet bestaat, met strict=False returned het None\n",
    "    client.makedirs('hdfs456')\n",
    "\n",
    "# hier geen /user/bigdata nodig omdat we zijn ingelogd als de bigdata user -> standaard zitten in zijn directory namelijk /user/bigdata\n",
    "\n",
    "# exists: hdfs dfs -test -d hdfs_path\n",
    "# create: hdfs dfs -mkdir -p /bigdata/HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make files\n",
    "client.upload('hdfs456', 'davinci_notebooks.txt', overwrite=True) # bestand bestaat al -> error -> check met behulp van status of het bestaat of gebruik overwrite parameter\n",
    "client.upload('hdfs456/boek2.txt', 'outline_of_science.txt', overwrite=True) # als je een pad geeft naar iets dat niet bestaat, dan wordt het hernoemd naar de opgegeven naa\n",
    "client.upload('hdfs456/boek3.txt', 'ulysses.txt', overwrite=True) # schrijf de file\n",
    "client.write('hdfs456/boek4.txt', 'ulysses.txt', overwrite=True) # schrijf data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Bekijken van het filesysteem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accessTime': 1740061883702, 'blockSize': 134217728, 'childrenNum': 0, 'fileId': 16436, 'group': 'supergroup', 'length': 11, 'modificationTime': 1740061883731, 'owner': 'bigdata', 'pathSuffix': '', 'permission': '644', 'replication': 3, 'storagePolicy': 0, 'type': 'FILE'}\n",
      "{'entries': [], 'group': 'supergroup', 'owner': 'bigdata', 'permission': '644', 'stickyBit': False}\n",
      "{'algorithm': 'MD5-of-0MD5-of-512CRC32C', 'bytes': '000002000000000000000000fb1d52cd3af9c4cf8e77e21537e9a41800000000', 'length': 28}\n",
      "['boek2.txt', 'boek3.txt', 'boek4.txt', 'davinci_notebooks.txt']\n",
      "<generator object Client.walk at 0x7ff209437680>\n",
      "('/', ['rmstate', 'user'], [])\n",
      "('/rmstate', ['FSRMStateRoot'], [])\n",
      "('/rmstate/FSRMStateRoot', ['AMRMTokenSecretManagerRoot', 'ProxyCARoot', 'RMAppRoot', 'RMDTSecretManagerRoot', 'ReservationSystemRoot'], ['EpochNode', 'RMVersionNode'])\n",
      "('/rmstate/FSRMStateRoot/AMRMTokenSecretManagerRoot', [], ['AMRMTokenSecretManagerNode'])\n",
      "('/rmstate/FSRMStateRoot/ProxyCARoot', [], ['caCert', 'caPrivateKey'])\n",
      "('/rmstate/FSRMStateRoot/RMAppRoot', [], [])\n",
      "('/rmstate/FSRMStateRoot/RMDTSecretManagerRoot', [], ['DelegationKey_1', 'DelegationKey_2', 'DelegationKey_3', 'DelegationKey_4', 'DelegationKey_5', 'DelegationKey_6'])\n",
      "('/rmstate/FSRMStateRoot/ReservationSystemRoot', [], [])\n",
      "('/user', ['bigdata'], [])\n",
      "('/user/bigdata', ['hdfs', 'hdfs456', 'hdfscli'], [])\n",
      "('/user/bigdata/hdfs', [], ['notebooks.txt'])\n",
      "('/user/bigdata/hdfs456', [], ['boek2.txt', 'boek3.txt', 'boek4.txt', 'davinci_notebooks.txt'])\n",
      "('/user/bigdata/hdfscli', [], [])\n"
     ]
    }
   ],
   "source": [
    "# hdfs dfs -ls command\n",
    "\n",
    "print(client.status('hdfs456/boek4.txt'))\n",
    "print(client.acl_status('hdfs456/boek4.txt'))\n",
    "print(client.checksum('hdfs456/boek4.txt'))\n",
    "print(client.list('hdfs456'))\n",
    "print(client.walk('/'))\n",
    "\n",
    "for f in client.walk('/'):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uitlezen van het filesysteem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'ulysses.txt'\n"
     ]
    }
   ],
   "source": [
    "client.download('hdfs456/boek4.txt', 'test.txt', overwrite=True) # maakt een lokale file aan\n",
    "\n",
    "with client.read('hdfs456/boek4.txt') as reader:\n",
    "    content=reader.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aanpassen van het filesysteem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#client.delete('hdfs', recursive=True)\n",
    "\n",
    "#client.rename('hdfs456/boek2.txt', 'hdfs456/boek.txt') # dit kan trouwens ook gebruikt worden om te verplaatsen\n",
    "\n",
    "client.set_permission('hdfs456/boek4.txt', 777)\n",
    "client.set_replication('hdfs456/boek4.txt', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oefening\n",
    "\n",
    "Los de volgende oefeningen op:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schrijf een Python-script dat de informatie van een bestand in HDFS ophaalt en weergeeft. De informatie moet onder andere de grootte van het bestand, de eigenaar, de groep en de permissies bevatten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schrijf een Python-script dat de volledige inhoud van een tekstbestand in HDFS leest en afdrukt naar de console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schrijf een Python-script dat een tekstbestand van de lokale schijf naar HDFS schrijft. Het script moet de inhoud van het lokale bestand lezen en deze naar een nieuw bestand in HDFS schrijven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schrijf een Python-script dat de permissies van een bestand in HDFS wijzigt. Het script moet de permissies instellen op een door de gebruiker opgegeven waarde (bijvoorbeeld 755)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schrijf een Python-script dat de huidige replicatiefactor van een bestand in HDFS controleert en weergeeft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schrijf een Python-script dat alle bestanden in een HDFS-directory zoekt die voldoen aan een bepaald naamspatroon (bijvoorbeeld alle .txt bestanden)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schrijf een Python-script dat nieuwe inhoud toevoegt aan een bestaand bestand in HDFS. Het script moet de nieuwe inhoud aan het einde van het bestand toevoegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schrijf een Python-script dat de checksum van een bestand in HDFS ophaalt en weergeeft. Dit kan nuttig zijn om de integriteit van bestanden te controleren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Schrijf python code dat controleert of een directory bestaat in het hdfs.\n",
    "Indien nee wordt de directory aangemaakt.\n",
    "Indien ja, worden alle files in de directory verwijderd om van een lege directory te starten.\n",
    "Upload daarna een tekst-bestand naar keuze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5e8e3a19af5ceb2434683dff87da6345c3b29f7eb0a8a138558c07d014a01cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
